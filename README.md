# UIDAI_Data_Hackathon2026

UIDAI Hackathon 2026: Aadhar Data Analytics & Forecasting Engine

ğŸ“Œ Project Overview
This repository hosts an end-to-end Data Intelligence Pipeline developed for the UIDAI Data Hackathon 2026. It is designed to ingest raw, noisy Aadhar administrative data (Enrolment, Biometric, and Demographic updates), sanitize it using fuzzy logic, and derive high-value actionable insights using Machine Learning.

ğŸ‘‰The system addresses three critical challenges in large-scale government datasets:

ğŸ‘‰Data Quality: Automated cleaning of inconsistent State/District names.

ğŸ‘‰Fraud Detection: Unsupervised learning to flag anomalous volume spikes.

ğŸ‘‰Resource Planning: AI-driven forecasting of future footfall for 2026.

ğŸš€ Key Features

ğŸ‘‰Self-Healing Data: Uses FuzzyWuzzy and Levenshtein distance to automatically merge variations like "West Bengal" and "west bengal" without manual dictionaries.

ğŸ‘‰Unified Master Dataset: Merges disparate CSV sources (Biometric, Demographic, Enrolment) into a single analytical source of truth.

ğŸ‘‰Anomaly Detection: Implements an Isolation Forest algorithm to detect statistical outliers (potential fraud or "ghost" centres) in the top 1% of transactions.

ğŸ‘‰Predictive Modeling: Uses Gradient Boosting Regressors to forecast daily footfall for the next 365 days, accounting for seasonal and weekly cyclic patterns.

âš™ï¸ Setup & Installation
Clone the repository

Bash

git clone https://github.com/yourusername/uidai-hackathon-2026.git

cd uidai-hackathon-2026

Install dependencies

Bash

pip install pandas numpy matplotlib seaborn scikit-learn fuzzywuzzy python-Levenshtein

Prepare Data

Create a folder named raw_data.

Place all your source CSV files inside it.

âš¡ Execution Pipeline (How to Run)

Follow this order to replicate the results:

1. Data Cleaning (ETL)
Standardizes spelling and removes duplicates.
